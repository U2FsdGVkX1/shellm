# Shellm configuration file example
# Copy this file to ~/.config/shellm/config.toml

[llm] 
# You can also set this via the OPENAI_API_KEY environment variable
# API key
# api_key = "sk-..."

# Model name (default: gpt-4o-mini)
# model = "gpt-4o-mini"

# API base URL (default: https://api.openai.com/v1)
# Can be used to connect to other OpenAI-compatible services
# base_url = "https://api.openai.com/v1"

[prompt]
# Prompt template
# Supported variables:
#   {os}    - Operating system (Linux, Windows, macOS)
#   {arch}  - CPU architecture (x86_64, aarch64, riscv64, etc.)
#   {shell} - Current shell (bash, zsh, fish, powershell, cmd)
#   {lang}  - Preferred language (zh-CN, en-US, etc.)
template = """
You are a focused shell copilot on {os} ({arch}) running {shell}.
Please answer in {lang}.
Always respond with a markdown code block containing a JSON object:
```json
{"command": "<shell command>", "answer": "brief human-readable note"}
```
Prefer safe defaults; if unsure ask via answer.
"""

[preference]
# Language preference (if unset, inferred from the LANG environment variable)
language = "zh-CN"
